1
00:00:00,000 --> 00:00:01,560
Welcome to this course on

2
00:00:01,560 --> 00:00:04,845
generative AI with large language models.

3
00:00:04,845 --> 00:00:06,960
Large language models or LLMs

4
00:00:06,960 --> 00:00:09,180
are a very exciting technology.

5
00:00:09,180 --> 00:00:11,475
But despite all the buzz and hype,

6
00:00:11,475 --> 00:00:13,950
one of the thing that is still underestimated by

7
00:00:13,950 --> 00:00:17,940
many people is their power as a developer too.

8
00:00:17,940 --> 00:00:19,500
Specifically, there are

9
00:00:19,500 --> 00:00:21,210
many machine learning and AI

10
00:00:21,210 --> 00:00:23,040
applications that used to take me

11
00:00:23,040 --> 00:00:25,515
many months to build that you can now build

12
00:00:25,515 --> 00:00:28,395
in days or maybe even small numbers of weeks.

13
00:00:28,395 --> 00:00:32,400
This course will take a deep dive with you into how

14
00:00:32,400 --> 00:00:34,605
LLM technology actually works

15
00:00:34,605 --> 00:00:38,040
including going through many of the technical details,

16
00:00:38,040 --> 00:00:42,175
like model training, instruction tuning, fine-tuning,

17
00:00:42,175 --> 00:00:45,740
the generative AI project life cycle framework to

18
00:00:45,740 --> 00:00:49,970
help you plan and execute your projects and so on.

19
00:00:49,970 --> 00:00:52,190
Generative AI and LLMs

20
00:00:52,190 --> 00:00:55,445
specifically are a general purpose technology.

21
00:00:55,445 --> 00:00:57,320
That means that similar to

22
00:00:57,320 --> 00:00:59,285
other general purpose technologies

23
00:00:59,285 --> 00:01:01,940
like deep learning and electricity,

24
00:01:01,940 --> 00:01:04,640
is useful not just for a single application,

25
00:01:04,640 --> 00:01:05,690
but for a lot of

26
00:01:05,690 --> 00:01:07,550
different applications that span

27
00:01:07,550 --> 00:01:10,060
many corners of the economy.

28
00:01:10,060 --> 00:01:13,380
Similar to the rise of deep learning that

29
00:01:13,380 --> 00:01:16,560
started maybe 15 years ago or so,

30
00:01:16,560 --> 00:01:19,850
there's a lot of important where it lies ahead of us that

31
00:01:19,850 --> 00:01:23,090
needs to be done over many years by many people,

32
00:01:23,090 --> 00:01:24,320
I hope including you,

33
00:01:24,320 --> 00:01:28,900
to identify use cases and build specific applications.

34
00:01:28,900 --> 00:01:31,760
Because a lot of with this technology is so

35
00:01:31,760 --> 00:01:34,855
new and so few people really know how to use them,

36
00:01:34,855 --> 00:01:36,950
many companies are also right

37
00:01:36,950 --> 00:01:38,900
now scrambling to try to find and

38
00:01:38,900 --> 00:01:40,805
hire people that actually know

39
00:01:40,805 --> 00:01:43,160
how to build applications with LLMs.

40
00:01:43,160 --> 00:01:46,415
I hope that this course will also help you,

41
00:01:46,415 --> 00:01:48,290
if you wish, better position

42
00:01:48,290 --> 00:01:50,525
yourself to get one of those jobs.

43
00:01:50,525 --> 00:01:53,000
I'm thrilled to bring you this course along with

44
00:01:53,000 --> 00:01:56,225
a group of fantastic instructors from the AWS team,

45
00:01:56,225 --> 00:02:01,700
[inaudible] who are here with me today,

46
00:02:01,700 --> 00:02:04,565
as well as a fourth instructor Chris Freby,

47
00:02:04,565 --> 00:02:06,515
who will be presenting sort of adds.

48
00:02:06,515 --> 00:02:11,530
Antje and Mike above generative AI developer advocates.

49
00:02:11,530 --> 00:02:13,715
Shelbee and Chris above

50
00:02:13,715 --> 00:02:16,130
generative AI solutions architects.

51
00:02:16,130 --> 00:02:17,720
All of them have a lot of

52
00:02:17,720 --> 00:02:21,050
experience helping many different companies build many,

53
00:02:21,050 --> 00:02:23,480
many creative applications using LLMs.

54
00:02:23,480 --> 00:02:26,300
I look forward to all of them sharing

55
00:02:26,300 --> 00:02:29,740
this rich hands-on experience in this course.

56
00:02:29,740 --> 00:02:31,400
We've develop the content for

57
00:02:31,400 --> 00:02:33,230
this course with inputs from

58
00:02:33,230 --> 00:02:37,640
many industry experts and applied scientists at Amazon,

59
00:02:37,640 --> 00:02:39,620
AWS, Hugging Face and

60
00:02:39,620 --> 00:02:41,740
many top universities around the world.

61
00:02:41,740 --> 00:02:43,160
Antje, perhaps you can say a

62
00:02:43,160 --> 00:02:44,600
bit more about this course.

63
00:02:44,600 --> 00:02:45,905
Sure. Thanks Andrew.

64
00:02:45,905 --> 00:02:48,560
It's a pleasure to work with you again on this course and

65
00:02:48,560 --> 00:02:51,290
the exciting area of generative AI.

66
00:02:51,290 --> 00:02:52,460
With this course on

67
00:02:52,460 --> 00:02:54,935
generative AI with large language models,

68
00:02:54,935 --> 00:02:56,750
we've created a series of

69
00:02:56,750 --> 00:02:59,150
lessons meant for AI enthusiasts,

70
00:02:59,150 --> 00:03:01,260
engineers, or data scientists.

71
00:03:01,260 --> 00:03:03,995
Looking to learn the technical foundations

72
00:03:03,995 --> 00:03:05,750
of how LLMs work,

73
00:03:05,750 --> 00:03:08,555
as well as the best practices behind training,

74
00:03:08,555 --> 00:03:10,550
tuning, and deploying them.

75
00:03:10,550 --> 00:03:12,050
In terms of prerequisites,

76
00:03:12,050 --> 00:03:14,120
we assume you are already familiar with

77
00:03:14,120 --> 00:03:16,340
Python programming and at least

78
00:03:16,340 --> 00:03:19,445
basic data science and machine learning concepts.

79
00:03:19,445 --> 00:03:21,230
If you have some experience with

80
00:03:21,230 --> 00:03:24,560
either Python or TensorFlow, that should be enough.

81
00:03:24,560 --> 00:03:28,520
In this course, you will explore in detail the steps that

82
00:03:28,520 --> 00:03:32,305
make up a typical generative AI project lifecycle,

83
00:03:32,305 --> 00:03:34,040
from scoping the problem and

84
00:03:34,040 --> 00:03:36,290
selecting a language model to

85
00:03:36,290 --> 00:03:37,490
optimizing a model for

86
00:03:37,490 --> 00:03:40,475
deployment and integrating into your applications.

87
00:03:40,475 --> 00:03:42,710
This course covers all of the topics,

88
00:03:42,710 --> 00:03:44,315
not just at a shallow level,

89
00:03:44,315 --> 00:03:46,880
but we'll take the time to make sure you come

90
00:03:46,880 --> 00:03:49,850
away with a deep technical understanding of

91
00:03:49,850 --> 00:03:53,240
all of these technologies and be well-positioned to

92
00:03:53,240 --> 00:03:55,190
really know what you're doing when you

93
00:03:55,190 --> 00:03:57,260
build your own generative AI projects.

94
00:03:57,260 --> 00:03:58,730
Mike, why don't you tell us

95
00:03:58,730 --> 00:04:00,185
a little bit more details about

96
00:04:00,185 --> 00:04:01,970
what the learners will see in each week?

97
00:04:01,970 --> 00:04:04,275
Absolutely, Antje. Thank you.

98
00:04:04,275 --> 00:04:06,500
In Week 1, you will examine

99
00:04:06,500 --> 00:04:08,450
the transformer architecture that

100
00:04:08,450 --> 00:04:10,595
powers large language models,

101
00:04:10,595 --> 00:04:13,220
explore how these models are trained,

102
00:04:13,220 --> 00:04:15,710
and understand the compute resources

103
00:04:15,710 --> 00:04:18,815
required to develop these powerful LLMs.

104
00:04:18,815 --> 00:04:20,600
You'll also learn about

105
00:04:20,600 --> 00:04:23,465
a technique called in-context learning.

106
00:04:23,465 --> 00:04:26,045
How to guide the model to output

107
00:04:26,045 --> 00:04:29,045
at inference time with prompt engineering,

108
00:04:29,045 --> 00:04:30,680
and how to tune

109
00:04:30,680 --> 00:04:33,275
the most important generation parameters

110
00:04:33,275 --> 00:04:36,350
of LLMs for tuning your model output.

111
00:04:36,350 --> 00:04:37,610
In Week 2,

112
00:04:37,610 --> 00:04:41,450
you'll explore options for adapting pre-trained models to

113
00:04:41,450 --> 00:04:44,000
specific tasks and datasets via

114
00:04:44,000 --> 00:04:47,270
a process called instruction fine tuning.

115
00:04:47,270 --> 00:04:48,680
Then in Week 3,

116
00:04:48,680 --> 00:04:50,120
you'll see how to align

117
00:04:50,120 --> 00:04:52,445
the output of language models with

118
00:04:52,445 --> 00:04:54,890
human values in order to increase

119
00:04:54,890 --> 00:04:58,850
helpfulness and decrease potential harm and toxicity.

120
00:04:58,850 --> 00:05:01,025
Though we don't stop at the theory.

121
00:05:01,025 --> 00:05:03,680
Each week includes a hands-on lab

122
00:05:03,680 --> 00:05:06,080
where you'll be able to try out these techniques for

123
00:05:06,080 --> 00:05:09,605
yourself in an AWS environment that includes

124
00:05:09,605 --> 00:05:12,290
all the resources you need for working with

125
00:05:12,290 --> 00:05:15,395
large models at no cost to you.

126
00:05:15,395 --> 00:05:16,850
Shelbee, can you tell us a little

127
00:05:16,850 --> 00:05:18,350
bit more about the hands-on labs?

128
00:05:18,350 --> 00:05:21,665
Sure thing, Mike. In the first hands-on lab,

129
00:05:21,665 --> 00:05:22,970
you'll construct a compare

130
00:05:22,970 --> 00:05:25,745
different prompts and inputs for a given generative task,

131
00:05:25,745 --> 00:05:27,725
in this case, dialogue summarization.

132
00:05:27,725 --> 00:05:29,960
You'll also explore different inference parameters

133
00:05:29,960 --> 00:05:31,670
and sampling strategies to gain

134
00:05:31,670 --> 00:05:33,500
intuition on how to further

135
00:05:33,500 --> 00:05:36,055
improve the generative model of responses.

136
00:05:36,055 --> 00:05:37,910
In the second hands-on lab,

137
00:05:37,910 --> 00:05:39,440
you'll find tune it existing

138
00:05:39,440 --> 00:05:41,420
large language model from Hugging Face,

139
00:05:41,420 --> 00:05:43,700
a popular open-source model hub.

140
00:05:43,700 --> 00:05:46,310
You'll play with both full fine-tuning and

141
00:05:46,310 --> 00:05:49,220
parameter efficient fine tuning or path for short.

142
00:05:49,220 --> 00:05:51,170
You'll see how puffed lets you

143
00:05:51,170 --> 00:05:53,530
make your workflow much more efficient.

144
00:05:53,530 --> 00:05:56,420
In the third lab, you get hands-on with reinforcement

145
00:05:56,420 --> 00:05:59,105
learning from human feedback or RLHF,

146
00:05:59,105 --> 00:06:01,910
you'll build a reward model classifier to label

147
00:06:01,910 --> 00:06:04,865
model responses as either toxic or non-toxic.

148
00:06:04,865 --> 00:06:06,290
Don't worry if you don't understand

149
00:06:06,290 --> 00:06:08,250
all these terms and concepts just yet.

150
00:06:08,250 --> 00:06:10,100
You'll dive into each of these topics in

151
00:06:10,100 --> 00:06:12,445
much more detail throughout this course.

152
00:06:12,445 --> 00:06:15,345
I'm thrilled to have Antje, Mike,

153
00:06:15,345 --> 00:06:18,740
Shelbee as well as Tris presenting this course to

154
00:06:18,740 --> 00:06:22,670
you that takes a deep technical dive into LLMs.

155
00:06:22,670 --> 00:06:25,850
You come away from this course having practice with

156
00:06:25,850 --> 00:06:27,980
many different concrete code examples

157
00:06:27,980 --> 00:06:29,750
for how to build or use LLMs.

158
00:06:29,750 --> 00:06:32,390
I'm sure that many of the code snippets will

159
00:06:32,390 --> 00:06:35,405
end up being directly useful in your own work.

160
00:06:35,405 --> 00:06:38,120
I hope you enjoy the course and use what

161
00:06:38,120 --> 00:06:41,015
you learn to build some really exciting applications.

162
00:06:41,015 --> 00:06:44,240
So that, let's go on to the next video where we start

163
00:06:44,240 --> 00:06:46,190
diving into how LLMs

164
00:06:46,190 --> 00:06:49,290
are being used to build applications.
